name: CI with Testing and Benchmarks

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

# Add permissions at workflow level
permissions:
  contents: read
  pull-requests: write  # Allow writing comments to PRs
  issues: write         # Allow writing to issues (PRs are issues)

jobs:
  # Main build, test, and benchmark job
  build-test-benchmark:
    name: ${{ matrix.os }} - ${{ matrix.compiler }}
    runs-on: ${{ matrix.os }}
    
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        compiler: [gcc, clang]
        exclude:
          - os: windows-latest
            compiler: gcc
          - os: windows-latest
            compiler: clang
        include:
          - os: windows-latest
            compiler: msvc
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    # Install ccache on Linux
    - name: Install ccache (Linux)
      if: runner.os == 'Linux'
      run: |
        sudo apt-get update
        sudo apt-get install -y ccache
    
    # Install ccache on macOS
    - name: Install ccache (macOS)
      if: runner.os == 'macOS'
      run: brew install ccache
    
    # Setup ccache with automatic caching
    - name: Setup ccache
      if: runner.os != 'Windows'
      uses: hendrikmuhs/ccache-action@v1.2
      with:
        key: ${{ runner.os }}-${{ matrix.compiler }}-bench
        max-size: 500M
    
    # Cache CMake build dependencies (Catch2, Google Benchmark)
    - name: Cache CMake dependencies
      uses: actions/cache@v4
      with:
        path: |
          build/_deps
        key: ${{ runner.os }}-cmake-deps-${{ hashFiles('**/CMakeLists.txt') }}
        restore-keys: |
          ${{ runner.os }}-cmake-deps-
    
    # Set up compiler for Linux
    - name: Set up compiler (Linux)
      if: runner.os == 'Linux'
      run: |
        if [ "${{ matrix.compiler }}" = "gcc" ]; then
          echo "CC=gcc" >> $GITHUB_ENV
          echo "CXX=g++" >> $GITHUB_ENV
        else
          echo "CC=clang" >> $GITHUB_ENV
          echo "CXX=clang++" >> $GITHUB_ENV
        fi
        # Enable ccache for CMake
        echo "CMAKE_CXX_COMPILER_LAUNCHER=ccache" >> $GITHUB_ENV
        echo "CMAKE_C_COMPILER_LAUNCHER=ccache" >> $GITHUB_ENV
    
    # Set up compiler for macOS
    - name: Set up compiler (macOS)
      if: runner.os == 'macOS'
      run: |
        if [ "${{ matrix.compiler }}" = "gcc" ]; then
          brew install gcc
          echo "CC=gcc-13" >> $GITHUB_ENV
          echo "CXX=g++-13" >> $GITHUB_ENV
        else
          echo "CC=clang" >> $GITHUB_ENV
          echo "CXX=clang++" >> $GITHUB_ENV
        fi
        # Enable ccache for CMake
        echo "CMAKE_CXX_COMPILER_LAUNCHER=ccache" >> $GITHUB_ENV
        echo "CMAKE_C_COMPILER_LAUNCHER=ccache" >> $GITHUB_ENV
    
    # Configure CMake with benchmarks enabled
    - name: Configure CMake
      run: cmake -B build -DCMAKE_BUILD_TYPE=Release -DBUILD_BENCHMARKS=ON
    
    # Build the project
    - name: Build
      run: cmake --build build --config Release
    
    # Run tests with verbose output
    - name: Run tests
      run: ctest --test-dir build --build-config Release --output-on-failure --verbose
    
    # Run tests with Catch2 reporter for detailed output
    - name: Run Catch2 tests with detailed output
      if: runner.os != 'Windows'
      run: ./build/tests/tests --reporter console
      continue-on-error: true
    
    - name: Run Catch2 tests with detailed output (Windows)
      if: runner.os == 'Windows'
      run: .\build\tests\Release\tests.exe --reporter console
      continue-on-error: true
    
    # Run benchmarks (only on Linux with GCC for consistency)
    - name: Run benchmarks
      if: runner.os == 'Linux' && matrix.compiler == 'gcc'
      run: |
        ./build/benchmark/mathlib_benchmarks \
          --benchmark_format=json \
          --benchmark_out=benchmark_results.json \
          --benchmark_repetitions=3 \
          --benchmark_report_aggregates_only=true
    
    # Upload benchmark results as artifact
    - name: Upload benchmark results
      if: runner.os == 'Linux' && matrix.compiler == 'gcc'
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results-${{ github.sha }}
        path: benchmark_results.json
    
    # Store baseline for main branch
    - name: Store baseline (main branch only)
      if: runner.os == 'Linux' && matrix.compiler == 'gcc' && github.ref == 'refs/heads/main'
      run: |
        mkdir -p benchmark_baselines
        cp benchmark_results.json benchmark_baselines/baseline_main.json
    
    - name: Upload baseline
      if: runner.os == 'Linux' && matrix.compiler == 'gcc' && github.ref == 'refs/heads/main'
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-baseline
        path: benchmark_baselines/baseline_main.json
    
    # Show ccache statistics
    - name: ccache statistics
      if: runner.os != 'Windows'
      run: ccache -s

  # Compare benchmarks on pull requests
  compare-benchmarks:
    name: Compare Performance
    runs-on: ubuntu-latest
    needs: build-test-benchmark
    if: github.event_name == 'pull_request'
    
    # Ensure this job has the necessary permissions
    permissions:
      contents: read
      pull-requests: write
      issues: write
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.x'
    
    # Download current benchmark results
    - name: Download current benchmark results
      uses: actions/download-artifact@v4
      with:
        name: benchmark-results-${{ github.sha }}
        path: ./current
    
    # Try to get baseline from main branch
    - name: Download baseline from main
      uses: dawidd6/action-download-artifact@v3
      with:
        workflow: ci.yml
        branch: main
        name: benchmark-baseline
        path: ./baseline
      continue-on-error: true
    
    # Compare benchmarks if we have a baseline
    - name: Compare benchmarks
      if: hashFiles('./baseline/baseline_main.json') != ''
      run: |
        python3 scripts/compare_benchmarks.py \
          ./baseline/baseline_main.json \
          ./current/benchmark_results.json \
          --threshold 1.20 \
          --warning-threshold 1.10 \
          > comparison_report.txt 2>&1 || true
    
    # Post comparison as PR comment
    - name: Comment PR with benchmark results
      if: hashFiles('./baseline/baseline_main.json') != ''
      uses: actions/github-script@v7
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const fs = require('fs');
          
          let report = '';
          try {
            report = fs.readFileSync('comparison_report.txt', 'utf8');
          } catch (err) {
            report = 'Error reading comparison report: ' + err.message;
          }
          
          // Truncate if too long (GitHub has a limit)
          const maxLength = 65000;
          if (report.length > maxLength) {
            report = report.substring(0, maxLength) + '\n\n... (truncated)';
          }
          
          const body = '## üìä Performance Benchmark Results\n\n```\n' + report + '\n```';
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: body
          });
    
    # If no baseline, just show current results
    - name: Show current results (no baseline)
      if: hashFiles('./baseline/baseline_main.json') == ''
      run: |
        echo "No baseline found - this is likely the first benchmark run."
        echo "Current benchmark results will be saved as baseline when this PR is merged."
        if [ -f ./current/benchmark_results.json ]; then
          echo ""
          echo "Current benchmarks:"
          python3 -c "import json; data = json.load(open('./current/benchmark_results.json')); print('\n'.join([f\"{b['name']}: {b.get('cpu_time', b.get('real_time', 0)):.2f} {b.get('time_unit', 'ns')}\" for b in data.get('benchmarks', []) if 'BigO' not in b.get('name', '') and 'RMS' not in b.get('name', '')]))"
        fi
    
    - name: Comment PR - no baseline
      if: hashFiles('./baseline/baseline_main.json') == ''
      uses: actions/github-script@v7
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const body = `## üìä Performance Benchmark Results
          
          ‚ÑπÔ∏è **No baseline found** - this is likely the first benchmark run.
          
          Current benchmark results will be saved as baseline when this PR is merged to main.
          Subsequent PRs will show performance comparisons against this baseline.
          
          ‚úÖ Benchmarks ran successfully and will establish the baseline.`;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: body
          });